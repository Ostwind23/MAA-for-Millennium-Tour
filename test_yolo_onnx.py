"""
YOLO ONNX å®æ—¶æ£€æµ‹å¯è§†åŒ–å·¥å…·

ç”¨äºæµ‹è¯• YOLO æ¨¡å‹åœ¨å®é™…æ¸¸æˆç”»é¢ä¸­çš„æ£€æµ‹æ•ˆæœã€‚
å®æ—¶æ˜¾ç¤ºæ¨¡æ‹Ÿå™¨ç”»é¢å¹¶æ ‡æ³¨æ£€æµ‹åˆ°çš„ç›®æ ‡ã€‚

ä½¿ç”¨æ–¹æ³•:
    python test_yolo_onnx.py

åŠŸèƒ½:
- å®æ—¶æˆªå›¾å¹¶æ˜¾ç¤ºæ¨¡æ‹Ÿå™¨ç”»é¢
- ä½¿ç”¨ YOLO ONNX æ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹
- åœ¨ç”»é¢ä¸Šç»˜åˆ¶æ£€æµ‹æ¡†å’Œæ ‡ç­¾
- æ˜¾ç¤ºæ£€æµ‹ç»“æœçš„è¯¦ç»†ä¿¡æ¯ï¼ˆç±»åˆ«ã€ç½®ä¿¡åº¦ã€åæ ‡ï¼‰
- ä¸æ‰§è¡Œä»»ä½•æ§åˆ¶æ“ä½œï¼Œä»…ç”¨äºè§‚å¯Ÿå’Œæµ‹è¯•

å¿«æ·é”®:
- ESC æˆ–å…³é—­çª—å£: é€€å‡ºç¨‹åº
- S: ä¿å­˜å½“å‰å¸§åˆ°æ–‡ä»¶


"""

import os
import sys
import time
import numpy as np
import cv2
import tkinter as tk
from PIL import Image, ImageTk, ImageDraw, ImageFont
from pathlib import Path

# æ·»åŠ  agent ç›®å½•åˆ° Python è·¯å¾„
_CURRENT_DIR = Path(__file__).parent
_AGENT_DIR = _CURRENT_DIR / "agent"
sys.path.insert(0, str(_AGENT_DIR))

# å¯¼å…¥ MaaFramework
from maa.context import Context
from maa.tasker import Tasker
from maa.resource import Resource
from maa.controller import AdbController
from maa.toolkit import Toolkit

# å¯¼å…¥ ONNX Runtime
try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    print("âŒ é”™è¯¯: onnxruntime æœªå®‰è£…ï¼")
    print("è¯·å®‰è£…: pip install onnxruntime-gpu")
    sys.exit(1)

# ==================== é…ç½® ====================
# æ¨¡å‹é…ç½®
MODEL_PATH = _CURRENT_DIR / "assets" / "resource" / "model" / "detect" / "farming.onnx"
YOLO_LABELS = ["bugs", "girl"]  # æ¨¡å‹ç±»åˆ«æ ‡ç­¾
YOLO_THRESHOLD = 0.3  # æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
YOLO_INPUT_SIZE = 640  # YOLOv8 è¾“å…¥å°ºå¯¸
YOLO_NMS_THRESHOLD = 0.45  # NMS IOU é˜ˆå€¼

# æ˜¾ç¤ºé…ç½®
SCREEN_WIDTH = 1280
SCREEN_HEIGHT = 720
WINDOW_TITLE = "YOLO ONNX Real-time Detection Viewer"
FPS_TARGET = 10  # ç›®æ ‡å¸§ç‡
FRAME_INTERVAL = 1.0 / FPS_TARGET  # å¸§é—´éš”

# é¢œè‰²é…ç½® (RGB)
COLORS = {
    "bugs": (255, 0, 0),    # çº¢è‰²
    "girl": (0, 255, 0),    # ç»¿è‰²
    "info": (255, 255, 255), # ç™½è‰²
    "fps": (255, 255, 0),   # é»„è‰²
}

# è°ƒè¯•è¾“å‡ºç›®å½•
DEBUG_OUTPUT_DIR = _CURRENT_DIR / "assets" / "debug" / "yolo_test"
DEBUG_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)


# ==================== YOLO æ¨ç†ç±» ====================
class YOLODetector:
    """YOLO æ£€æµ‹å™¨ï¼ˆä½¿ç”¨ ONNX Runtimeï¼‰"""
    
    def __init__(self, model_path: Path):
        self.model_path = model_path
        self.session = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½ ONNX æ¨¡å‹"""
        if not self.model_path.exists():
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            sys.exit(1)
        
        print(f"ğŸ“¦ åŠ è½½ ONNX æ¨¡å‹: {self.model_path}")
        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
        
        try:
            self.session = ort.InferenceSession(str(self.model_path), providers=providers)
            print(f"âœ… ä½¿ç”¨ Provider: {self.session.get_providers()}")
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            sys.exit(1)
    
    def preprocess(self, image: np.ndarray):
        """é¢„å¤„ç†å›¾åƒ"""
        h, w = image.shape[:2]
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        scale = min(YOLO_INPUT_SIZE / w, YOLO_INPUT_SIZE / h)
        new_w = int(w * scale)
        new_h = int(h * scale)
        
        # ç¼©æ”¾
        resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # å¡«å……
        pad_w = (YOLO_INPUT_SIZE - new_w) // 2
        pad_h = (YOLO_INPUT_SIZE - new_h) // 2
        
        padded = np.full((YOLO_INPUT_SIZE, YOLO_INPUT_SIZE, 3), 114, dtype=np.uint8)
        padded[pad_h:pad_h+new_h, pad_w:pad_w+new_w] = resized
        
        # BGR -> RGB -> CHW -> å½’ä¸€åŒ– -> æ·»åŠ  batch ç»´åº¦
        rgb = cv2.cvtColor(padded, cv2.COLOR_BGR2RGB)
        chw = rgb.transpose(2, 0, 1)
        normalized = chw.astype(np.float32) / 255.0
        batched = np.expand_dims(normalized, axis=0)
        
        return batched, scale, pad_w, pad_h
    
    def postprocess(self, output: np.ndarray, scale: float, pad_w: int, pad_h: int):
        """åå¤„ç† YOLO è¾“å‡º"""
        # å¤„ç†è¾“å‡ºæ ¼å¼
        if len(output.shape) == 3 and output.shape[0] == 1:
            output = output[0]
        
        if output.shape[0] < output.shape[1]:  # (6, 8400)
            output = output.transpose(1, 0)  # -> (8400, 6)
        
        # æå–ä¿¡æ¯
        boxes = output[:, :4]  # (8400, 4)
        class_scores = output[:, 4:]  # (8400, num_classes)
        
        class_ids = np.argmax(class_scores, axis=1)
        confidences = np.max(class_scores, axis=1)
        
        # è¿‡æ»¤ä½ç½®ä¿¡åº¦
        mask = confidences > YOLO_THRESHOLD
        if not mask.any():
            return []
        
        boxes = boxes[mask]
        confidences = confidences[mask]
        class_ids = class_ids[mask]
        
        # è½¬æ¢åæ ‡: ä¸­å¿ƒç‚¹ -> å·¦ä¸Šè§’
        x_centers, y_centers = boxes[:, 0], boxes[:, 1]
        widths, heights = boxes[:, 2], boxes[:, 3]
        
        x1 = x_centers - widths / 2
        y1 = y_centers - heights / 2
        
        # åå‘å˜æ¢: å»é™¤å¡«å……å’Œç¼©æ”¾
        x1 = (x1 - pad_w) / scale
        y1 = (y1 - pad_h) / scale
        widths = widths / scale
        heights = heights / scale
        
        # NMS
        boxes_for_nms = np.stack([x1, y1, widths, heights], axis=1).astype(np.float32)
        indices = cv2.dnn.NMSBoxes(
            boxes_for_nms.tolist(),
            confidences.tolist(),
            YOLO_THRESHOLD,
            YOLO_NMS_THRESHOLD
        )
        
        if len(indices) == 0:
            return []
        
        # æ„å»ºç»“æœ
        results = []
        for i in indices.flatten():
            class_id = int(class_ids[i])
            label = YOLO_LABELS[class_id] if class_id < len(YOLO_LABELS) else f"class_{class_id}"
            
            results.append({
                "label": label,
                "class_id": class_id,
                "confidence": float(confidences[i]),
                "box": [int(x1[i]), int(y1[i]), int(widths[i]), int(heights[i])]
            })
        
        return results
    
    def detect(self, image: np.ndarray):
        """æ‰§è¡Œæ£€æµ‹"""
        # é¢„å¤„ç†
        input_tensor, scale, pad_w, pad_h = self.preprocess(image)
        
        # æ¨ç†
        input_name = self.session.get_inputs()[0].name
        output_names = [output.name for output in self.session.get_outputs()]
        
        outputs = self.session.run(output_names, {input_name: input_tensor})
        output = outputs[0]
        
        # åå¤„ç†
        detections = self.postprocess(output, scale, pad_w, pad_h)
        
        return detections


# ==================== å¯è§†åŒ–çª—å£ ====================
class DetectionViewer:
    """æ£€æµ‹ç»“æœå¯è§†åŒ–çª—å£"""
    
    def __init__(self, detector: YOLODetector, controller):
        self.detector = detector
        self.controller = controller
        
        # åˆ›å»ºçª—å£
        self.root = tk.Tk()
        self.root.title(WINDOW_TITLE)
        self.root.geometry(f"{SCREEN_WIDTH}x{SCREEN_HEIGHT + 100}")  # é¢å¤–ç©ºé—´æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        
        # Canvas
        self.canvas = tk.Canvas(self.root, width=SCREEN_WIDTH, height=SCREEN_HEIGHT, bg='black')
        self.canvas.pack()
        
        # ç»Ÿè®¡ä¿¡æ¯ Label
        self.info_label = tk.Label(
            self.root, 
            text="", 
            font=("Consolas", 10), 
            bg='black', 
            fg='white',
            justify=tk.LEFT,
            anchor='w'
        )
        self.info_label.pack(fill=tk.BOTH, expand=True)
        
        # çŠ¶æ€
        self.running = True
        self.frame_count = 0
        self.fps = 0
        self.last_time = time.time()
        self.photo_image = None
        self.canvas_image_id = None
        
        # ç»‘å®šæŒ‰é”®
        self.root.bind('<Escape>', lambda e: self.stop())
        self.root.bind('s', lambda e: self.save_frame())
        self.root.bind('S', lambda e: self.save_frame())
        self.root.protocol("WM_DELETE_WINDOW", self.stop)
        
        print("\nğŸ“º çª—å£å·²åˆ›å»º")
        print("å¿«æ·é”®:")
        print("  - ESC æˆ–å…³é—­çª—å£: é€€å‡º")
        print("  - S: ä¿å­˜å½“å‰å¸§\n")
    
    def update_frame(self, image: np.ndarray, detections: list):
        """æ›´æ–°æ˜¾ç¤ºå¸§"""
        # è½¬æ¢ä¸º RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(image_rgb)
        
        # åˆ›å»ºå åŠ å±‚
        overlay = Image.new('RGBA', pil_image.size, (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for det in detections:
            label = det["label"]
            box = det["box"]
            confidence = det["confidence"]
            
            x, y, w, h = box
            color = COLORS.get(label, (128, 128, 128))
            
            # åŠé€æ˜å¡«å……
            draw.rectangle([x, y, x + w, y + h], fill=color + (60,))
            
            # è¾¹æ¡†
            draw.rectangle([x, y, x + w, y + h], outline=color + (255,), width=3)
            
            # æ ‡ç­¾
            text = f"{label} {confidence:.2f}"
            draw.text((x, y - 20), text, fill=color + (255,))
            
            # ä¸­å¿ƒç‚¹
            cx, cy = x + w // 2, y + h // 2
            draw.ellipse([cx - 5, cy - 5, cx + 5, cy + 5], fill=color + (255,))
        
        # åˆæˆ
        pil_image = pil_image.convert('RGBA')
        pil_image = Image.alpha_composite(pil_image, overlay)
        pil_image = pil_image.convert('RGB')
        
        # æ›´æ–° Canvas
        self.photo_image = ImageTk.PhotoImage(pil_image)
        if self.canvas_image_id:
            self.canvas.itemconfig(self.canvas_image_id, image=self.photo_image)
        else:
            self.canvas_image_id = self.canvas.create_image(0, 0, anchor=tk.NW, image=self.photo_image)
        
        # ä¿å­˜å½“å‰å¸§ä¾›æˆªå›¾ä½¿ç”¨
        self.current_display_image = pil_image
    
    def update_info(self, detections: list, inference_time: float):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        # ç»Ÿè®¡å„ç±»åˆ«æ•°é‡
        stats = {}
        for det in detections:
            label = det["label"]
            stats[label] = stats.get(label, 0) + 1
        
        # æ„å»ºä¿¡æ¯æ–‡æœ¬
        info_lines = [
            f"FPS: {self.fps:.1f} | Frame: {self.frame_count} | Inference: {inference_time*1000:.1f}ms",
            f"Detections: {len(detections)} | " + " | ".join([f"{k}: {v}" for k, v in stats.items()]),
            "",
            "Detection Details:"
        ]
        
        for i, det in enumerate(detections[:10]):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            label = det["label"]
            conf = det["confidence"]
            box = det["box"]
            info_lines.append(f"  [{i+1}] {label:8s} {conf:.3f}  box={box}")
        
        if len(detections) > 10:
            info_lines.append(f"  ... and {len(detections) - 10} more")
        
        self.info_label.config(text="\n".join(info_lines))
    
    def save_frame(self):
        """ä¿å­˜å½“å‰å¸§"""
        if hasattr(self, 'current_display_image'):
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = DEBUG_OUTPUT_DIR / f"frame_{timestamp}.png"
            self.current_display_image.save(filename)
            print(f"ğŸ’¾ å·²ä¿å­˜å¸§: {filename}")
    
    def run(self):
        """ä¸»å¾ªç¯"""
        print("ğŸš€ å¼€å§‹æ£€æµ‹å¾ªç¯...\n")
        
        def detection_loop():
            if not self.running:
                return
            
            loop_start = time.time()
            
            try:
                # æˆªå›¾
                self.controller.post_screencap().wait()
                image = self.controller.cached_image
                
                if image is not None:
                    # æ£€æµ‹
                    inference_start = time.time()
                    detections = self.detector.detect(image)
                    inference_time = time.time() - inference_start
                    
                    # æ›´æ–°æ˜¾ç¤º
                    self.update_frame(image, detections)
                    self.update_info(detections, inference_time)
                    
                    # æ›´æ–°å¸§è®¡æ•°å’Œ FPS
                    self.frame_count += 1
                    current_time = time.time()
                    if current_time - self.last_time >= 1.0:
                        self.fps = self.frame_count / (current_time - self.last_time)
                        self.frame_count = 0
                        self.last_time = current_time
            
            except Exception as e:
                print(f"âŒ æ£€æµ‹å¾ªç¯é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
            
            # æ§åˆ¶å¸§ç‡
            elapsed = time.time() - loop_start
            delay = max(10, int((FRAME_INTERVAL - elapsed) * 1000))
            self.root.after(delay, detection_loop)
        
        # å¯åŠ¨æ£€æµ‹å¾ªç¯
        self.root.after(100, detection_loop)
        
        # è¿›å…¥ Tkinter ä¸»å¾ªç¯
        self.root.mainloop()
    
    def stop(self):
        """åœæ­¢"""
        print("\nâ¹ï¸  åœæ­¢...")
        self.running = False
        if self.root:
            self.root.quit()


# ==================== ä¸»å‡½æ•° ====================
def main():
    print("=" * 60)
    print("    YOLO ONNX å®æ—¶æ£€æµ‹å¯è§†åŒ–å·¥å…·")
    print("=" * 60)
    
    # åˆå§‹åŒ– Toolkit
    Toolkit.init_option(_CURRENT_DIR / "assets" / "config")
    
    # æŸ¥æ‰¾ ADB è®¾å¤‡
    print("\nğŸ” æ‰«æ ADB è®¾å¤‡...")
    adb_devices = Toolkit.find_adb_devices()
    
    if not adb_devices:
        print("âŒ æœªæ‰¾åˆ° ADB è®¾å¤‡ï¼")
        print("è¯·ç¡®ä¿:")
        print("  1. æ¨¡æ‹Ÿå™¨å·²å¯åŠ¨")
        print("  2. ADB å·²è¿æ¥")
        sys.exit(1)
    
    print(f"âœ… æ‰¾åˆ° {len(adb_devices)} ä¸ªè®¾å¤‡:")
    for i, dev in enumerate(adb_devices):
        print(f"  [{i+1}] {dev.name} ({dev.adb_path})")
    
    # é€‰æ‹©è®¾å¤‡
    if len(adb_devices) == 1:
        selected_device = adb_devices[0]
        print(f"\nğŸ“± è‡ªåŠ¨é€‰æ‹©è®¾å¤‡: {selected_device.name}")
    else:
        while True:
            try:
                choice = int(input(f"\nè¯·é€‰æ‹©è®¾å¤‡ [1-{len(adb_devices)}]: "))
                if 1 <= choice <= len(adb_devices):
                    selected_device = adb_devices[choice - 1]
                    break
            except (ValueError, KeyboardInterrupt):
                print("\nâŒ å·²å–æ¶ˆ")
                sys.exit(0)
    
    # åˆ›å»ºæ§åˆ¶å™¨
    print(f"\nğŸ”Œ è¿æ¥åˆ°è®¾å¤‡: {selected_device.name}")
    controller = AdbController(
        adb_path=selected_device.adb_path,
        address=selected_device.address,
        screencap_methods=selected_device.screencap_methods,
        input_methods=selected_device.input_methods,
        config=selected_device.config
    )
    
    controller.post_connection().wait()
    print("âœ… è®¾å¤‡å·²è¿æ¥")
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨
    print(f"\nğŸ¤– åˆå§‹åŒ– YOLO æ£€æµ‹å™¨...")
    print(f"   æ¨¡å‹: {MODEL_PATH}")
    print(f"   ç±»åˆ«: {YOLO_LABELS}")
    print(f"   é˜ˆå€¼: {YOLO_THRESHOLD}")
    
    detector = YOLODetector(MODEL_PATH)
    
    # åˆ›å»ºå¯è§†åŒ–çª—å£
    viewer = DetectionViewer(detector, controller)
    
    # è¿è¡Œ
    try:
        viewer.run()
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­")
    finally:
        print("\nâœ… ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()
